{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Generating CXR Embeddings from ELIXR Models\n",
    "\n",
    "This notebook contains the deidentified code we used to generate embeddings using the [ELIXR](https://arxiv.org/pdf/2308.01317) [1] models from chest radiographs.\n",
    "\n",
    "Since the unique identifiers (UIDs) and the way they map to patients and DICOM files are institution dependent and we risk identifying subjects from our own clinical center, we provide only the code necessary to save the embeddings.\n",
    "\n",
    "Please find details regarding the models and weights from the [HuggingFace model card](https://huggingface.co/google/cxr-foundation) and the original authors' [GitHub repository](https://github.com/Google-Health/cxr-foundation).\n",
    "\n",
    "[1] Xu, Shawn, et al. \"Elixr: Towards a general purpose x-ray artificial intelligence system through alignment of large language models and radiology vision encoders.\" arXiv preprint arXiv:2308.01317 (2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pydicom import dcmread\n",
    "\n",
    "from huggingface_hub.utils import HfFolder\n",
    "from huggingface_hub import notebook_login\n",
    "import io\n",
    "import png\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import rescale_intensity, equalize_adapthist\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "warnings.simplefilter(action = 'ignore', category = Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from ELIXR authors\n",
    "# https://github.com/Google-Health/cxr-foundation/blob/master/notebooks/quick_start_with_hugging_face.ipynb\n",
    "# Helper function for processing image data\n",
    "def png_to_tfexample(image_array: np.ndarray) -> tf.train.Example:\n",
    "    \"\"\"Creates a tf.train.Example from a NumPy array.\"\"\"\n",
    "    # Convert the image to float32 and shift the minimum value to zero\n",
    "    image = image_array.astype(np.float32)\n",
    "    image -= image.min()\n",
    "\n",
    "    if image_array.dtype == np.uint8:\n",
    "        # For uint8 images, no rescaling is needed\n",
    "        pixel_array = image.astype(np.uint8)\n",
    "        bitdepth = 8\n",
    "    else:\n",
    "        # For other data types, scale image to use the full 16-bit range\n",
    "        max_val = image.max()\n",
    "        if max_val > 0:\n",
    "            image *= 65535 / max_val  # Scale to 16-bit range\n",
    "        pixel_array = image.astype(np.uint16)\n",
    "        bitdepth = 16\n",
    "\n",
    "    # Ensure the array is 2-D (grayscale image)\n",
    "    if pixel_array.ndim != 2:\n",
    "        raise ValueError(f'Array must be 2-D. Actual dimensions: {pixel_array.ndim}')\n",
    "\n",
    "    # Encode the array as a PNG image\n",
    "    output = io.BytesIO()\n",
    "    png.Writer(\n",
    "        width=pixel_array.shape[1],\n",
    "        height=pixel_array.shape[0],\n",
    "        greyscale=True,\n",
    "        bitdepth=bitdepth\n",
    "    ).write(output, pixel_array.tolist())\n",
    "    png_bytes = output.getvalue()\n",
    "\n",
    "    # Create a tf.train.Example and assign the features\n",
    "    example = tf.train.Example()\n",
    "    features = example.features.feature\n",
    "    features['image/encoded'].bytes_list.value.append(png_bytes)\n",
    "    features['image/format'].bytes_list.value.append(b'png')\n",
    "\n",
    "    return example\n",
    "\n",
    "# Code adapted from from ELIXR authors\n",
    "# https://github.com/Google-Health/cxr-foundation/blob/master/notebooks/quick_start_with_hugging_face.ipynb\n",
    "def get_elixr_models(hf_local_dir) :\n",
    "\n",
    "    # Download the model repository files\n",
    "    from huggingface_hub import snapshot_download\n",
    "    snapshot_download(repo_id=\"google/cxr-foundation\",local_dir = hf_local_dir,\n",
    "                    allow_patterns=['elixr-c-v2-pooled/*', 'pax-elixr-b-text/*'])\n",
    "\n",
    "    if 'elixrc_model' not in locals():\n",
    "        elixrc_model = tf.saved_model.load(os.path.join(hf_local_dir, 'elixr-c-v2-pooled'))\n",
    "\n",
    "    if 'qformer_model' not in locals():\n",
    "        qformer_model = tf.saved_model.load(os.path.join(hf_local_dir, 'pax-elixr-b-text'))\n",
    "\n",
    "    return elixrc_model, qformer_model\n",
    "\n",
    "# Code adapted from from ELIXR authors\n",
    "# https://github.com/Google-Health/cxr-foundation/blob/master/notebooks/quick_start_with_hugging_face.ipynb\n",
    "def embed_cxr(img, elixrc_model, qformer_model) :\n",
    "\n",
    "    serialized_img_tf_example = png_to_tfexample(np.array(img)).SerializeToString()\n",
    "\n",
    "    elixrc_infer = elixrc_model.signatures['serving_default']\n",
    "    elixrc_output = elixrc_infer(input_example=tf.constant([serialized_img_tf_example]))\n",
    "    elixrc_embedding = elixrc_output['feature_maps_0'].numpy()\n",
    "\n",
    "    # Step 2 - Invoke QFormer with Elixr-C embeddings\n",
    "    # Initialize text inputs with zeros\n",
    "    qformer_input = {\n",
    "        'image_feature': elixrc_embedding.tolist(),\n",
    "        'ids': np.zeros((1, 1, 128), dtype=np.int32).tolist(),\n",
    "        'paddings':np.zeros((1, 1, 128), dtype=np.float32).tolist(),\n",
    "    }\n",
    "\n",
    "    qformer_output = qformer_model.signatures['serving_default'](**qformer_input)\n",
    "    elixrb_embeddings = qformer_output['all_contrastive_img_emb'].numpy()\n",
    "\n",
    "    return elixrc_embedding, elixrb_embeddings\n",
    "\n",
    "def center_crop(img, out_dims = (224, 224)):\n",
    "\n",
    "    y,x = img.shape\n",
    "    y_start = y // 2 - (out_dims[0] // 2)    \n",
    "    x_start = x // 2 - (out_dims[1] // 2)\n",
    "    \n",
    "    return_val = img[y_start:y_start+out_dims[1],x_start:x_start+out_dims[0]]\n",
    "\n",
    "    assert return_val.shape == out_dims\n",
    "\n",
    "    return return_val\n",
    "\n",
    "def center_crop_to_short_edge(img) :\n",
    "\n",
    "    if img.shape[0] == img.shape[1] :\n",
    "\n",
    "        return img\n",
    "    \n",
    "    short_edge = min(img.shape)\n",
    "\n",
    "    return center_crop(img, out_dims = (short_edge, short_edge))\n",
    "\n",
    "def get_pixels_from_dcm(src, crop_to_short_edge = True, clahe_clip_limit = None, contrast_stretching = None, resize_dim = 1024) :\n",
    "\n",
    "    img = dcmread(src).pixel_array\n",
    "    \n",
    "    if crop_to_short_edge :\n",
    "        img = center_crop_to_short_edge(img)\n",
    "    if clahe_clip_limit :\n",
    "        img = equalize_adapthist(img, clip_limit = clahe_clip_limit)\n",
    "    if isinstance(contrast_stretching, tuple)  :\n",
    "        plow, phigh = np.percentile(img, (contrast_stretching[0], contrast_stretching[1]))\n",
    "        img = rescale_intensity(img, in_range=(plow, phigh))\n",
    "    if resize_dim :\n",
    "        img = resize(img, (resize_dim, resize_dim))\n",
    "    if not clahe_clip_limit :\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Define paths for data loading and saving\n",
    "COMBINED_TABLE_PATH = None\n",
    "COMBINED_DATA_FOLDER_PATH = None\n",
    "HF_LOCAL_DIR = None\n",
    "EMBEDDINGS_FOLDER_PATH = None\n",
    "\n",
    "# TO-DO: get list or array of file paths\n",
    "path_list = None\n",
    "assert os.path.isfile(path_list[0])\n",
    "\n",
    "embeddings_by_setting_path = os.path.join(EMBEDDINGS_FOLDER_PATH, f'cxr_embeddings')\n",
    "elixrc_cxr_embeddings_parent = os.path.join(embeddings_by_setting_path, 'elixrc_embeddings')\n",
    "elixrb_cxr_embeddings_parent = os.path.join(embeddings_by_setting_path, 'elixrb_embeddings')\n",
    "\n",
    "for path in [embeddings_by_setting_path, elixrb_cxr_embeddings_parent, elixrc_cxr_embeddings_parent] :\n",
    "    if not os.path.isdir(path) :\n",
    "        os.mkdir(path)\n",
    "        print(f'{path} created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elixrc_model, qformer_model = get_elixr_models(hf_local_dir = HF_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elixrc_cxr_embeddings = []\n",
    "elixrb_cxr_embeddings = []\n",
    "\n",
    "for i,src in enumerate(path_list) :\n",
    "\n",
    "    filename = f\"{src.split('.dcm')[0].split('/')[-1]}.pkl\"\n",
    "    elixrc_cxr_embedding_path = os.path.join(elixrc_cxr_embeddings_parent, filename)\n",
    "    elixrb_cxr_embedding_path = os.path.join(elixrb_cxr_embeddings_parent, filename)\n",
    "\n",
    "    if not (os.path.isfile(elixrc_cxr_embedding_path) and os.path.isfile(elixrb_cxr_embedding_path)) :\n",
    "\n",
    "        img = get_pixels_from_dcm(src, crop_to_short_edge = True, clahe_clip_limit = 0.2, resize_dim = 1284)\n",
    "        current_elixrc_embedding, current_elixrb_embedding = embed_cxr(img, elixrc_model, qformer_model)\n",
    "\n",
    "        with open(elixrc_cxr_embedding_path, 'wb') as handle:\n",
    "            pickle.dump(current_elixrc_embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        with open(elixrb_cxr_embedding_path, 'wb') as handle:\n",
    "            pickle.dump(current_elixrb_embedding, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    if (i % 250 == 0) or (i == len(path_list) - 1):\n",
    "        print(f'{i:>6} / {len(path_list)} complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
