{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8675564",
   "metadata": {},
   "source": [
    "# Notebook for Generating ECG Embeddings from ECG-FM\n",
    "\n",
    "This notebook contains the deidentified code we used to generate embeddings using the [ECG-FM](https://arxiv.org/abs/2408.05178) [1] models from standard 12-lead electrocardiograms.\n",
    "\n",
    "Since the unique identifiers (UIDs) and the way they map to patients and waveform files are institution dependent and we risk identifying subjects from our own clinical center, we provide only the code necessary to save the embeddings. Please note that our ECGs were already saved as `.npy` files before loading.\n",
    "\n",
    "Please find details regarding the models and weights from [HuggingFace](https://huggingface.co/wanglab/ecg-fm/tree/main) and the original authors' [GitHub repository](https://github.com/bowang-lab/ECG-FM). Additionally, you will want to reference the [`fairseq-signals`](https://github.com/Jwoo5/fairseq-signals) framework. You will have to use the environment in the `fairseq_signals_env.yaml` file or any appropriate `Python` environment with `fairseq-signals`.\n",
    "\n",
    "[1] McKeen, Kaden, et al. \"Ecg-fm: An open electrocardiogram foundation model.\" arXiv preprint arXiv:2408.05178 (2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from fairseq_signals.utils.store import MemmapReader\n",
    "from fairseq_signals.models import build_model_from_checkpoint\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3089382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ecg_dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, waveforms, labels):\n",
    "\n",
    "        self.waveforms = waveforms\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.waveforms)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        waveform = self.waveforms[idx]\n",
    "        waveform = torch.from_numpy(waveform).type(torch.FloatTensor)\n",
    "\n",
    "        label = self.labels[idx].astype(float)\n",
    "        label = torch.from_numpy(label).type(torch.FloatTensor)\n",
    "        \n",
    "        return {'waveform':waveform, 'label':label}\n",
    "\n",
    "def get_files_of_type(parent_path:str, filetype:str, as_dict:bool=False) :\n",
    "\n",
    "    assert os.path.isdir(parent_path), f'{parent_path} is not a valid directory.'\n",
    "\n",
    "    path_list = sorted([os.path.join(root,file) for root,_,files in os.walk(parent_path) for file in files if file.endswith(filetype)])\n",
    "\n",
    "    assert len(path_list) > 0, f'{parent_path} contains 0 files of file type {filetype}.'\n",
    "    \n",
    "    if as_dict :\n",
    "        \n",
    "        path_dict = {\".\".join(os.path.split(path)[-1].split(\".\")[:-1]):path for path in path_list}\n",
    "\n",
    "        return path_dict\n",
    "\n",
    "    return path_list\n",
    "\n",
    "\n",
    "# Code from original fairseq-signals auhtors\n",
    "# https://github.com/Jwoo5/fairseq-signals/blob/6b9e1375bbe6bc2e55ff4d9b95eabe8eee3adec7/scripts/preprocess/ecg/preprocess.py#L49C1-L62C77\n",
    "def resample(feats, curr_sample_rate, desired_sample_rate):\n",
    "    \"\"\"\n",
    "    Resample an ECG using linear interpolation.\n",
    "    \"\"\"\n",
    "    if curr_sample_rate == desired_sample_rate:\n",
    "        return feats\n",
    "\n",
    "    desired_sample_size = int(\n",
    "        feats.shape[-1] * (desired_sample_rate / curr_sample_rate)\n",
    "    )\n",
    "\n",
    "    x = np.linspace(0, desired_sample_size - 1, feats.shape[-1])\n",
    "\n",
    "    return interp1d(x, feats, kind='linear')(np.arange(desired_sample_size))\n",
    "\n",
    "# Code adapted from original fairseq-signals auhtors\n",
    "# https://github.com/Jwoo5/fairseq-signals/blob/6b9e1375bbe6bc2e55ff4d9b95eabe8eee3adec7/scripts/preprocess/ecg/preprocess.py#L139\n",
    "def lead_std_divide(feats, std = None, constant_lead_strategy='zero'):\n",
    "        \n",
    "    if not isinstance(std, np.ndarray) : \n",
    "        std = feats.std(axis=1, keepdims=True)\n",
    "    \n",
    "    std_zero = std == 0\n",
    "    \n",
    "    # Check if there are any zero stds or if strategy is 'nan'\n",
    "    if not std_zero.any() or constant_lead_strategy == 'nan':\n",
    "        # Directly divide, which will turn constant leads into NaN if any\n",
    "        feats = feats / std\n",
    "\n",
    "        return feats, std\n",
    "\n",
    "    # Replace zero standard deviations with 1 temporarily to avoid division by zero\n",
    "    std_replaced = np.where(std_zero, 1, std)\n",
    "    feats = feats / std_replaced\n",
    "\n",
    "    if constant_lead_strategy == 'zero':\n",
    "        # Replace constant leads to be 0\n",
    "        zero_mask = np.broadcast_to(std_zero, feats.shape)\n",
    "        feats[zero_mask] = 0\n",
    "\n",
    "    elif constant_lead_strategy == 'constant':\n",
    "        # Leave constant leads as is\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected constant lead strategy.\")\n",
    "\n",
    "    return feats, std\n",
    "\n",
    "def standard_normalize_ecg(waveform) :\n",
    "\n",
    "    waveform -= waveform.mean(axis = 1, keepdims = True)\n",
    "    waveform = lead_std_divide(waveform)[0]\n",
    "\n",
    "    return waveform\n",
    "\n",
    "# Code adapted from code by fairseq-signals authors\n",
    "# https://github.com/Jwoo5/fairseq-signals/blob/6b9e1375bbe6bc2e55ff4d9b95eabe8eee3adec7/fairseq_signals/models/classification/ecg_transformer_classifier.py#L55\n",
    "def sum_and_divide(x) :\n",
    "    return torch.div(x.sum(dim=1), (x != 0).sum(dim=1))\n",
    "\n",
    "def get_all_ecg_embeddings(model, train_loader, val_loader, test_loader) :\n",
    "\n",
    "    all_embeddings = {data_split:[] for data_split in ['train', 'val', 'test']}\n",
    "\n",
    "    for data_split,current_loader in [('train', train_loader), ('val', val_loader), ('test', test_loader)] :\n",
    "        for batch in current_loader :\n",
    "            waveform = batch['waveform'].cuda()\n",
    "            with torch.no_grad() :\n",
    "                emb = model(source = waveform)\n",
    "                emb = {k:v.cpu() if isinstance(v, torch.Tensor) and v.is_cuda else v for k,v in emb.items()}\n",
    "                all_embeddings[data_split].append(emb)\n",
    "\n",
    "    return all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0aaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Define paths for data loading and saving\n",
    "HF_LOCAL_DIR = None\n",
    "COMBINED_DATA_FOLDER_PATH = None\n",
    "EMBEDDINGS_FOLDER_PATH = None\n",
    "COMBINED_TABLE_PATH = None\n",
    "fairseq_signals_root = None\n",
    "\n",
    "assert os.path.isdir(HF_LOCAL_DIR)\n",
    "assert os.path.isdir(COMBINED_DATA_FOLDER_PATH)\n",
    "assert os.path.isdir(EMBEDDINGS_FOLDER_PATH)\n",
    "assert os.path.isdir(fairseq_signals_root)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f323a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm-preprint',\n",
    "    filename='mimic_iv_ecg_physionet_pretrained.pt',\n",
    "    local_dir=os.path.join(HF_LOCAL_DIR, 'ckpts'),\n",
    ")\n",
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm-preprint',\n",
    "    filename='mimic_iv_ecg_physionet_pretrained.yaml',\n",
    "    local_dir=os.path.join(HF_LOCAL_DIR, 'ckpts'),\n",
    ")\n",
    "\n",
    "model = build_model_from_checkpoint(checkpoint_path=os.path.join(HF_LOCAL_DIR, 'ckpts/mimic_iv_ecg_physionet_pretrained.pt'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"We sampled the waveforms at 500 Hz, performed z-score normalization, and segmented the signals into non-overlapping 5 s segments to produce the model inputs.\"\"\n",
    "# https://arxiv.org/abs/2408.05178\n",
    "current_sample_rate = 250\n",
    "desired_sample_rate = 500\n",
    "\n",
    "npy_paths = get_files_of_type(COMBINED_DATA_FOLDER_PATH, filetype = '.npy', as_dict = True)\n",
    "\n",
    "# TO-DO: Load data\n",
    "X_train = None\n",
    "y_train = None\n",
    "X_val = None\n",
    "y_val = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "\n",
    "if X_train.shape[1] == 1 :  X_train = X_train.squeeze(axis = 1)\n",
    "if X_val.shape[1] == 1 :  X_val = X_val.squeeze(axis = 1)\n",
    "if X_test.shape[1] == 1 :  X_test = X_test.squeeze(axis = 1)\n",
    "\n",
    "if X_train.shape[-1] == 12 : X_train = X_train.transpose(0, 2, 1)\n",
    "if X_val.shape[-1] == 12 : X_val = X_val.transpose(0, 2, 1)\n",
    "if X_test.shape[-1] == 12 : X_test = X_test.transpose(0, 2, 1)\n",
    "\n",
    "if current_sample_rate != desired_sample_rate :\n",
    "    X_train = np.array([resample(feats = waveform, curr_sample_rate = current_sample_rate, desired_sample_rate = desired_sample_rate) for waveform in X_train])\n",
    "    X_val = np.array([resample(feats = waveform, curr_sample_rate = current_sample_rate, desired_sample_rate = desired_sample_rate) for waveform in X_val])\n",
    "    X_test = np.array([resample(feats = waveform, curr_sample_rate = current_sample_rate, desired_sample_rate = desired_sample_rate) for waveform in X_test])\n",
    "\n",
    "X_train = np.array([standard_normalize_ecg(waveform) for waveform in X_train])\n",
    "X_val = np.array([standard_normalize_ecg(waveform) for waveform in X_val])\n",
    "X_test = np.array([standard_normalize_ecg(waveform) for waveform in X_test])\n",
    "\n",
    "print(f'{X_train.shape=} {X_val.shape=} {X_test.shape=}')\n",
    "\n",
    "train_dataset = ecg_dataset(waveforms = X_train, labels = y_train)\n",
    "val_dataset = ecg_dataset(waveforms = X_val, labels = y_val)\n",
    "test_dataset = ecg_dataset(waveforms = X_test, labels = y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1, shuffle = False)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 1, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ecg_embeddings_path = os.path.join(EMBEDDINGS_FOLDER_PATH, 'full_ecg_embeddings_dict.pkl')\n",
    "\n",
    "if not os.path.isfile(full_ecg_embeddings_path) :\n",
    "\n",
    "    all_embeddings = get_all_ecg_embeddings(model, train_loader, val_loader, test_loader)\n",
    "    \n",
    "    with open(full_ecg_embeddings_path, 'wb') as handle:\n",
    "        pickle.dump(all_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else :\n",
    "\n",
    "    with open(full_ecg_embeddings_path, 'rb') as handle:\n",
    "        all_embeddings = pickle.load(handle)\n",
    "\n",
    "processed_embbedings = {data_split:[sum_and_divide(emb['features']) for emb in all_embeddings[data_split]] for data_split in ['train', 'val', 'test']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairseq_signals_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
